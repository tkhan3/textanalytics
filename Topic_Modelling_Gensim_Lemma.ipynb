{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic Modelling Gensim Lemma.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tkhan3/textanalytics/blob/master/Topic_Modelling_Gensim_Lemma.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "VqIC8r4dfllc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Topic Modelling Resources**\n",
        "https://www.machinelearningplus.com/nlp/topic-modeling-python-sklearn-examples/\n",
        "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
        "https://towardsdatascience.com/natural-language-processing-using-stanfords-corenlp-d9e64c1e1024\n",
        "https://www.mien.in/2017/10/02/visual-text-analytics-with-python/\n",
        "https://learning.oreilly.com/library/view/applied-text-analysis/9781491963036/ch08.html\n",
        "https://medium.com/mlreview/topic-modeling-with-scikit-learn-e80d33668730\n",
        "https://www.analyticsvidhya.com/blog/2016/08/beginners-guide-to-topic-modeling-in-python/\n",
        "https://radimrehurek.com/gensim/wiki.html#latent-dirichlet-allocation\n",
        "https://stackoverflow.com/questions/6486738/clustering-using-latent-dirichlet-allocation-algo-in-gensim\n",
        "**Applied Text Analytics With Python: **https://learning.oreilly.com/library/view/applied-text-analysis/9781491963036/ch08.html\n",
        "https://www.analyticsvidhya.com/blog/2018/02/the-different-methods-deal-text-data-predictive-python/\n",
        "http://brandonrose.org/clustering\n",
        "https://scikit-learn.org/0.18/auto_examples/text/document_clustering.html\n",
        "http://brandonrose.org/clustering#Visualizing-document-clusters\n",
        "https://github.com/changwookjun/StudyBook/blob/master/NLPBooks/Applied%20Text%20Analysis%20with%20Python.pdf\n",
        "https://medium.com/sciforce/top-10-books-on-nlp-and-text-analysis-8393a9fd3f49\n",
        "https://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html#sphx-glr-auto-examples-cluster-plot-dbscan-py\n"
      ]
    },
    {
      "metadata": {
        "id": "NF6RZt0QLB_X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zP9GBHjzi8-t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "outputId": "c63781f6-3b6f-4caa-928c-ecd9c733b030"
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "#import pandas as pd\n",
        "!google-drive-ocamlfuse drive\n",
        "!apt-get -qq install -y graphviz && pip install -q pydot\n",
        "!pip3 install seaborn==0.9.0\n",
        "import pydot\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "!pip install sklearn_pandas"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 131322 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.1-0ubuntu3~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n",
            "Error: Mountpoint drive should be an existing directory.\n",
            "Collecting seaborn==0.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/76/220ba4420459d9c4c9c9587c6ce607bf56c25b3d3d2de62056efe482dadc/seaborn-0.9.0-py3-none-any.whl (208kB)\n",
            "\u001b[K    100% |████████████████████████████████| 215kB 28.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.15.2 in /usr/local/lib/python3.6/dist-packages (from seaborn==0.9.0) (0.22.0)\n",
            "Requirement already satisfied: numpy>=1.9.3 in /usr/local/lib/python3.6/dist-packages (from seaborn==0.9.0) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from seaborn==0.9.0) (1.1.0)\n",
            "Requirement already satisfied: matplotlib>=1.4.3 in /usr/local/lib/python3.6/dist-packages (from seaborn==0.9.0) (3.0.2)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.15.2->seaborn==0.9.0) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.15.2->seaborn==0.9.0) (2.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn==0.9.0) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn==0.9.0) (1.0.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn==0.9.0) (2.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas>=0.15.2->seaborn==0.9.0) (1.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn==0.9.0) (40.8.0)\n",
            "Installing collected packages: seaborn\n",
            "  Found existing installation: seaborn 0.7.1\n",
            "    Uninstalling seaborn-0.7.1:\n",
            "      Successfully uninstalled seaborn-0.7.1\n",
            "Successfully installed seaborn-0.9.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "seaborn"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting sklearn_pandas\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/48/4e1461d828baf41d609efaa720d20090ac6ec346b5daad3c88e243e2207e/sklearn_pandas-1.8.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from sklearn_pandas) (1.14.6)\n",
            "Requirement already satisfied: scikit-learn>=0.15.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_pandas) (0.20.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from sklearn_pandas) (1.1.0)\n",
            "Requirement already satisfied: pandas>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_pandas) (0.22.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.11.0->sklearn_pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.11.0->sklearn_pandas) (2.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas>=0.11.0->sklearn_pandas) (1.11.0)\n",
            "Installing collected packages: sklearn-pandas\n",
            "Successfully installed sklearn-pandas-1.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rUT_R-qflk9j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "d1fd6122-7c70-4d94-8cb4-b1aa514c8be3"
      },
      "cell_type": "code",
      "source": [
        "!pip install pyLDAvis"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyLDAvis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/3a/af82e070a8a96e13217c8f362f9a73e82d61ac8fff3a2561946a97f96266/pyLDAvis-2.1.2.tar.gz (1.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.6MB 14.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.33.1)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.1.0)\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.22.0)\n",
            "Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.13.2)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (2.10)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (2.6.9)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (3.10.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Collecting funcy (from pyLDAvis)\n",
            "  Downloading https://files.pythonhosted.org/packages/47/a4/204fa23012e913839c2da4514b92f17da82bf5fc8c2c3d902fa3fa3c6eec/funcy-1.11-py2.py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.0->pyLDAvis) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.0->pyLDAvis) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (6.0.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.8.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (18.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.11.0)\n",
            "Requirement already satisfied: pluggy>=0.7 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (0.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (40.8.0)\n",
            "Building wheels for collected packages: pyLDAvis\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/98/71/24/513a99e58bb6b8465bae4d2d5e9dba8f0bef8179e3051ac414\n",
            "Successfully built pyLDAvis\n",
            "Installing collected packages: funcy, pyLDAvis\n",
            "Successfully installed funcy-1.11 pyLDAvis-2.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rvWDBSjXkb4n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Run in terminal or command prompt\n",
        "# python3 -m spacy download en\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re, nltk, spacy, gensim\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from pprint import pprint\n",
        "\n",
        "# Plotting tools\n",
        "import pyLDAvis\n",
        "import pyLDAvis.sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oCBQa4HjuHg6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def clean_up(rec):\n",
        "  table = str.maketrans({key: None for key in string.punctuation})\n",
        "  rec = str(rec)\n",
        "  rec = rec.replace('\\n',' ').replace('\\r',' ')\n",
        "  #rec = rec.replace('\\S+@\\S+',' ')\n",
        "  rec = re.sub(r'[^a-zA-Z0-9\\.,;?<>/ ]',r'',rec)\n",
        "  rec = re.sub(r'\\w*\\d\\w*', '', rec)\n",
        "  rec = rec.strip()\n",
        "  rec = re.sub(' +', ' ',rec)\n",
        "  rec = rec.translate(table)\n",
        "  rec = rec.lower()\n",
        "  return rec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mWbCW15yl59m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "95108fa9-80bc-46ea-923d-4ef135846154"
      },
      "cell_type": "code",
      "source": [
        "# Import Dataset\n",
        "df = pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')\n",
        "print(df.target_names.unique())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['rec.autos' 'comp.sys.mac.hardware' 'rec.motorcycles' 'misc.forsale'\n",
            " 'comp.os.ms-windows.misc' 'alt.atheism' 'comp.graphics'\n",
            " 'rec.sport.baseball' 'rec.sport.hockey' 'sci.electronics' 'sci.space'\n",
            " 'talk.politics.misc' 'sci.med' 'talk.politics.mideast'\n",
            " 'soc.religion.christian' 'comp.windows.x' 'comp.sys.ibm.pc.hardware'\n",
            " 'talk.politics.guns' 'talk.religion.misc' 'sci.crypt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4gGAoszkmHru",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "21c3cec4-a669-428d-bc7d-599e3a0f8c95"
      },
      "cell_type": "code",
      "source": [
        "df.head(15)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>target</th>\n",
              "      <th>target_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
              "      <td>7</td>\n",
              "      <td>rec.autos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
              "      <td>4</td>\n",
              "      <td>comp.sys.mac.hardware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>From: irwin@cmptrc.lonestar.org (Irwin Arnstei...</td>\n",
              "      <td>8</td>\n",
              "      <td>rec.motorcycles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>From: tchen@magnus.acs.ohio-state.edu (Tsung-K...</td>\n",
              "      <td>6</td>\n",
              "      <td>misc.forsale</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000</th>\n",
              "      <td>From: dabl2@nlm.nih.gov (Don A.B. Lindbergh)\\n...</td>\n",
              "      <td>2</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10000</th>\n",
              "      <td>From: a207706@moe.dseg.ti.com (Robert Loper)\\n...</td>\n",
              "      <td>7</td>\n",
              "      <td>rec.autos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10001</th>\n",
              "      <td>From: kimman@magnus.acs.ohio-state.edu (Kim Ri...</td>\n",
              "      <td>6</td>\n",
              "      <td>misc.forsale</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10002</th>\n",
              "      <td>From: kwilson@casbah.acns.nwu.edu (Kirtley Wil...</td>\n",
              "      <td>2</td>\n",
              "      <td>comp.os.ms-windows.misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10003</th>\n",
              "      <td>Subject: Re: Don't more innocents die without ...</td>\n",
              "      <td>0</td>\n",
              "      <td>alt.atheism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10004</th>\n",
              "      <td>From: livesey@solntze.wpd.sgi.com (Jon Livesey...</td>\n",
              "      <td>0</td>\n",
              "      <td>alt.atheism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10005</th>\n",
              "      <td>From: dls@aeg.dsto.gov.au (David Silver)\\nSubj...</td>\n",
              "      <td>1</td>\n",
              "      <td>comp.graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10006</th>\n",
              "      <td>Subject: Re: Mike Francesa's 1993 Predictions\\...</td>\n",
              "      <td>9</td>\n",
              "      <td>rec.sport.baseball</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10007</th>\n",
              "      <td>From: jet@netcom.Netcom.COM (J. Eric Townsend)...</td>\n",
              "      <td>8</td>\n",
              "      <td>rec.motorcycles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10008</th>\n",
              "      <td>From: gld@cunixb.cc.columbia.edu (Gary L Dare)...</td>\n",
              "      <td>10</td>\n",
              "      <td>rec.sport.hockey</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10009</th>\n",
              "      <td>From: sehari@iastate.edu (Babak Sehari)\\nSubje...</td>\n",
              "      <td>12</td>\n",
              "      <td>sci.electronics</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 content  target  \\\n",
              "0      From: lerxst@wam.umd.edu (where's my thing)\\nS...       7   \n",
              "1      From: guykuo@carson.u.washington.edu (Guy Kuo)...       4   \n",
              "10     From: irwin@cmptrc.lonestar.org (Irwin Arnstei...       8   \n",
              "100    From: tchen@magnus.acs.ohio-state.edu (Tsung-K...       6   \n",
              "1000   From: dabl2@nlm.nih.gov (Don A.B. Lindbergh)\\n...       2   \n",
              "10000  From: a207706@moe.dseg.ti.com (Robert Loper)\\n...       7   \n",
              "10001  From: kimman@magnus.acs.ohio-state.edu (Kim Ri...       6   \n",
              "10002  From: kwilson@casbah.acns.nwu.edu (Kirtley Wil...       2   \n",
              "10003  Subject: Re: Don't more innocents die without ...       0   \n",
              "10004  From: livesey@solntze.wpd.sgi.com (Jon Livesey...       0   \n",
              "10005  From: dls@aeg.dsto.gov.au (David Silver)\\nSubj...       1   \n",
              "10006  Subject: Re: Mike Francesa's 1993 Predictions\\...       9   \n",
              "10007  From: jet@netcom.Netcom.COM (J. Eric Townsend)...       8   \n",
              "10008  From: gld@cunixb.cc.columbia.edu (Gary L Dare)...      10   \n",
              "10009  From: sehari@iastate.edu (Babak Sehari)\\nSubje...      12   \n",
              "\n",
              "                  target_names  \n",
              "0                    rec.autos  \n",
              "1        comp.sys.mac.hardware  \n",
              "10             rec.motorcycles  \n",
              "100               misc.forsale  \n",
              "1000   comp.os.ms-windows.misc  \n",
              "10000                rec.autos  \n",
              "10001             misc.forsale  \n",
              "10002  comp.os.ms-windows.misc  \n",
              "10003              alt.atheism  \n",
              "10004              alt.atheism  \n",
              "10005            comp.graphics  \n",
              "10006       rec.sport.baseball  \n",
              "10007          rec.motorcycles  \n",
              "10008         rec.sport.hockey  \n",
              "10009          sci.electronics  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "Z2dNILlvmWdm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Convert to list\n",
        "data = df.content.values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "18ho5FaSva-4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "9c881154-a356-4b86-9cfa-b2ad63f6f6ff"
      },
      "cell_type": "code",
      "source": [
        "data[1:5]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"From: guykuo@carson.u.washington.edu (Guy Kuo)\\nSubject: SI Clock Poll - Final Call\\nSummary: Final call for SI clock reports\\nKeywords: SI,acceleration,clock,upgrade\\nArticle-I.D.: shelley.1qvfo9INNc3s\\nOrganization: University of Washington\\nLines: 11\\nNNTP-Posting-Host: carson.u.washington.edu\\n\\nA fair number of brave souls who upgraded their SI clock oscillator have\\nshared their experiences for this poll. Please send a brief message detailing\\nyour experiences with the procedure. Top speed attained, CPU rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.\\n\\nI will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven't answered this\\npoll. Thanks.\\n\\nGuy Kuo <guykuo@u.washington.edu>\\n\",\n",
              " 'From: irwin@cmptrc.lonestar.org (Irwin Arnstein)\\nSubject: Re: Recommendation on Duc\\nSummary: What\\'s it worth?\\nDistribution: usa\\nExpires: Sat, 1 May 1993 05:00:00 GMT\\nOrganization: CompuTrac Inc., Richardson TX\\nKeywords: Ducati, GTS, How much? \\nLines: 13\\n\\nI have a line on a Ducati 900GTS 1978 model with 17k on the clock.  Runs\\nvery well, paint is the bronze/brown/orange faded out, leaks a bit of oil\\nand pops out of 1st with hard accel.  The shop will fix trans and oil \\nleak.  They sold the bike to the 1 and only owner.  They want $3495, and\\nI am thinking more like $3K.  Any opinions out there?  Please email me.\\nThanks.  It would be a nice stable mate to the Beemer.  Then I\\'ll get\\na jap bike and call myself Axis Motors!\\n\\n-- \\n-----------------------------------------------------------------------\\n\"Tuba\" (Irwin)      \"I honk therefore I am\"     CompuTrac-Richardson,Tx\\nirwin@cmptrc.lonestar.org    DoD #0826          (R75/6)\\n-----------------------------------------------------------------------\\n',\n",
              " \"From: tchen@magnus.acs.ohio-state.edu (Tsung-Kun Chen)\\nSubject: ** Software forsale (lots) **\\nNntp-Posting-Host: magnusug.magnus.acs.ohio-state.edu\\nOrganization: The Ohio State University\\n    ****   This is a post for my friend,  You can either call    ****\\n    ****    him  J.K Lee  (614)791-0748    or Drop me a mail     ****\\nDistribution: usa\\nLines: 39\\n\\n1.  Software publishing SuperBase 4 windows v.1.3           --->$80\\n\\n2.  OCR System ReadRight v.3.1 for Windows                  --->$65\\n\\n3.  OCR System ReadRight  v.2.01 for DOS                    --->$65\\n\\n4.  Unregistered Zortech 32 bit C++ Compiler v.3.1          --->$ 250\\n     with Multiscope windows Debugger,\\n     WhiteWater Resource Toolkit, Library Source Code\\n\\n5.  Glockenspiel/ImageSoft Commonview 2 Windows\\n     Applications Framework for Borland C++                 --->$70\\n\\n6.  Spontaneous Assembly Library With Source Code           --->$50\\n\\n7.  Microsoft Macro Assembly 6.0                            --->$50\\n\\n8.  Microsoft Windows v.3.1 SDK Documentation               --->$125\\n\\n9.  Microsoft FoxPro V.2.0                                  --->$75\\n\\n10.  WordPerfect 5.0 Developer's Toolkit                    --->$20\\n\\n11.  Kedwell Software DataBoss v.3.5 C Code Generator       --->$100\\n\\n12.  Kedwell InstallBoss v.2.0 Installation Generator       --->$35\\n\\n13.  Liant Software C++/Views v.2.1\\n       Windows Application Framework with Source Code       --->$195\\n\\n14.  IBM OS/2 2.0 & Developer's Toolkit                     --->$95\\n\\n15.  CBTree DOS/Windows Library with Source Code            --->$120\\n\\n16.  Symantec TimeLine for Windows                          --->$90\\n\\n17.  TimeSlip TimeSheet Professional for Windows            --->$30\\n\\n         Many More Software/Books Available,Price Negotiable\\n\",\n",
              " \"From: dabl2@nlm.nih.gov (Don A.B. Lindbergh)\\nSubject: Diamond SS24X, Win 3.1, Mouse cursor\\nOrganization: National Library of Medicine\\nLines: 10\\n\\n\\nAnybody seen mouse cursor distortion running the Diamond 1024x768x256 driver?\\nSorry, don't know the version of the driver (no indication in the menus) but it's a recently\\ndelivered Gateway system.  Am going to try the latest drivers from Diamond BBS but wondered\\nif anyone else had seen this.\\n\\npost or email\\n\\n--Don Lindbergh\\ndabl2@lhc.nlm.nih.gov\\n\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "2nC8RvLcuqJO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_cleanned = [clean_up(item) for item in data]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y-RZ7XFnvOyF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "84c0d520-4811-4063-ed03-23d0ff07652c"
      },
      "cell_type": "code",
      "source": [
        "data_cleanned[1:5]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['from guykuocarsonuwashingtonedu guy kuo subject si clock poll final call summary final call for si clock reports keywords siaccelerationclockupgrade articleid shelley organization university of washington lines nntppostinghost carsonuwashingtonedu a fair number of brave souls who upgraded their si clock oscillator have shared their experiences for this poll please send a brief message detailing your experiences with the procedure top speed attained cpu rated speed add on cards and adapters heat sinks hour of usage per day floppy disk functionality with and  m floppies are especially requested i will be summarizing in the next two days so please add to the network knowledge base if you have done the clock upgrade and havent answered this poll thanks guy kuo guykuouwashingtonedu',\n",
              " 'from irwincmptrclonestarorg irwin arnstein subject re recommendation on duc summary whats it worth distribution usa expires sat may gmt organization computrac inc richardson tx keywords ducati gts how much lines i have a line on a ducati model with on the clock runs very well paint is the bronzebrownorange faded out leaks a bit of oil and pops out of with hard accel the shop will fix trans and oil leak they sold the bike to the and only owner they want  and i am thinking more like  any opinions out there please email me thanks it would be a nice stable mate to the beemer then ill get a jap bike and call myself axis motors tuba irwin i honk therefore i am computracrichardsontx irwincmptrclonestarorg dod ',\n",
              " 'from tchenmagnusacsohiostateedu tsungkun chen subject software forsale lots nntppostinghost magnusugmagnusacsohiostateedu organization the ohio state university this is a post for my friend you can either call him jk lee or drop me a mail distribution usa lines  software publishing superbase windows v   ocr system readright v for windows   ocr system readright v for dos   unregistered zortech bit c compiler v  with multiscope windows debugger whitewater resource toolkit library source code  glockenspielimagesoft commonview windows applications framework for borland c   spontaneous assembly library with source code   microsoft macro assembly    microsoft windows v sdk documentation   microsoft foxpro v   wordperfect  developers toolkit   kedwell software databoss v c code generator   kedwell installboss v installation generator   liant software cviews v windows application framework with source code   ibm os  developers toolkit   cbtree doswindows library with source code   symantec timeline for windows   timeslip timesheet professional for windows  many more softwarebooks availableprice negotiable',\n",
              " 'from nihgov don ab lindbergh subject diamond  win  mouse cursor organization national library of medicine lines anybody seen mouse cursor distortion running the diamond driver sorry dont know the version of the driver no indication in the menus but its a recently delivered gateway system am going to try the latest drivers from diamond bbs but wondered if anyone else had seen this post or email don lindbergh nlmnihgov']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "YKY8FFC7xFSD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "62ec2261-a051-49f2-d11e-c42ab16fb361"
      },
      "cell_type": "code",
      "source": [
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "data_words = list(sent_to_words(data_cleanned))\n",
        "\n",
        "print(data_words[:1])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['from', 'lerxstwamumdedu', 'wheres', 'my', 'thing', 'subject', 'what', 'car', 'is', 'this', 'nntppostinghost', 'wamumdedu', 'organization', 'university', 'of', 'maryland', 'college', 'park', 'lines', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'saw', 'the', 'other', 'day', 'it', 'was', 'sports', 'car', 'looked', 'to', 'be', 'from', 'the', 'late', 'early', 'it', 'was', 'called', 'bricklin', 'the', 'doors', 'were', 'really', 'small', 'in', 'addition', 'the', 'front', 'bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', 'this', 'is', 'all', 'know', 'if', 'anyone', 'can', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is', 'made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'email', 'thanks', 'il', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'lerxst']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ottp5LGpxN3S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3332e293-8407-45a5-de74-d56c3bcdf6ff"
      },
      "cell_type": "code",
      "source": [
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append(\" \".join([token.lemma_ if token.lemma_ not in ['-PRON-'] else '' for token in doc if token.pos_ in allowed_postags]))\n",
        "    return texts_out\n",
        "\n",
        "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
        "# Run in terminal: python3 -m spacy download en\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "\n",
        "# Do lemmatization keeping only Noun, Adj, Verb, Adverb\n",
        "data_lemmatized = lemmatization(data_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "\n",
        "print(data_lemmatized[:2])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['lerxstwamumdedu where s  thing subject what car be nntppostinghost wamumdedu organization university maryland college park line be wonder anyone out there could enlighten car see other day be sport car look be late early be call bricklin door be really small addition front bumper be separate rest body be know anyone can tellme model name engine spec year production where car be make history whatev info have funky look car email thank bring  neighborhood lerxst', 'guy subject clock poll final call summary final call si clock report keyword articleid shelley organization university washington line nntppostinghost fair number brave soul who upgrade  si clock oscillator have share  experience poll send brief message detail  experience procedure top speed attain cpu rat speed add card adapter heat sink hour usage day floppy disk functionality floppy be especially request will be summarize next day so add network knowledge base have do clock upgrade have not answer poll thank guy kuo']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "onhir9lIxaeI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(analyzer='word',       \n",
        "                             min_df=10,                        # minimum reqd occurences of a word \n",
        "                             stop_words='english',             # remove stop words\n",
        "                             lowercase=True,                   # convert all words to lowercase\n",
        "                             token_pattern='[a-zA-Z0-9]{3,}',  # num chars > 3\n",
        "                             # max_features=50000,             # max number of uniq words\n",
        "                            )\n",
        "\n",
        "data_vectorized = vectorizer.fit_transform(data_lemmatized)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mWH-IL9jyXBu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74291561-a7a1-4b4f-d549-a9b2d139580d"
      },
      "cell_type": "code",
      "source": [
        "# Materialize the sparse data\n",
        "data_dense = data_vectorized.todense()\n",
        "\n",
        "# Compute Sparsicity = Percentage of Non-Zero cells\n",
        "print(\"Sparsicity: \", ((data_dense > 0).sum()/data_dense.size)*100, \"%\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sparsicity:  0.7438066100095797 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nDqUpWbGybjq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "a60328ba-3b2b-4e0c-aabd-522c62777ad6"
      },
      "cell_type": "code",
      "source": [
        "# Build LDA Model\n",
        "lda_model = LatentDirichletAllocation(n_topics=20,               # Number of topics\n",
        "                                      max_iter=10,               # Max learning iterations\n",
        "                                      learning_method='online',   \n",
        "                                      random_state=100,          # Random state\n",
        "                                      batch_size=128,            # n docs in each learning iter\n",
        "                                      evaluate_every = -1,       # compute perplexity every n iters, default: Don't\n",
        "                                      n_jobs = -1,               # Use all available CPUs\n",
        "                                     )\n",
        "lda_output = lda_model.fit_transform(data_vectorized)\n",
        "\n",
        "print(lda_model)  # Model attributes"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/online_lda.py:314: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
            "             evaluate_every=-1, learning_decay=0.7,\n",
            "             learning_method='online', learning_offset=10.0,\n",
            "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
            "             n_components=10, n_jobs=-1, n_topics=20, perp_tol=0.1,\n",
            "             random_state=100, topic_word_prior=None,\n",
            "             total_samples=1000000.0, verbose=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AXqPwBuayjzs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "3d4c4190-c76e-44d0-f019-7db5731b19e1"
      },
      "cell_type": "code",
      "source": [
        "# Log Likelyhood: Higher the better\n",
        "print(\"Log Likelihood: \", lda_model.score(data_vectorized))\n",
        "\n",
        "# Perplexity: Lower the better. Perplexity = exp(-1. * log-likelihood per word)\n",
        "print(\"Perplexity: \", lda_model.perplexity(data_vectorized))\n",
        "\n",
        "# See model parameters\n",
        "pprint(lda_model.get_params())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Log Likelihood:  -9427853.102365388\n",
            "Perplexity:  2098.587894016431\n",
            "{'batch_size': 128,\n",
            " 'doc_topic_prior': None,\n",
            " 'evaluate_every': -1,\n",
            " 'learning_decay': 0.7,\n",
            " 'learning_method': 'online',\n",
            " 'learning_offset': 10.0,\n",
            " 'max_doc_update_iter': 100,\n",
            " 'max_iter': 10,\n",
            " 'mean_change_tol': 0.001,\n",
            " 'n_components': 10,\n",
            " 'n_jobs': -1,\n",
            " 'n_topics': 20,\n",
            " 'perp_tol': 0.1,\n",
            " 'random_state': 100,\n",
            " 'topic_word_prior': None,\n",
            " 'total_samples': 1000000.0,\n",
            " 'verbose': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8cJzOJinzE27",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "5a333a7e-f1e1-48e8-8bcc-2c63a6d5d108"
      },
      "cell_type": "code",
      "source": [
        "# Define Search Param\n",
        "search_params = {'n_components': [10, 15, 20, 25, 30], 'learning_decay': [.5, .7, .9]}\n",
        "\n",
        "# Init the Model\n",
        "lda = LatentDirichletAllocation()\n",
        "\n",
        "# Init Grid Search Class\n",
        "model = GridSearchCV(lda, param_grid=search_params)\n",
        "\n",
        "# Do the Grid Search\n",
        "model.fit(data_vectorized)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
            "  warnings.warn(CV_WARNING, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "6X9whWtPzUG9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Best Model\n",
        "best_lda_model = model.best_estimator_\n",
        "\n",
        "# Model Parameters\n",
        "print(\"Best Model's Params: \", model.best_params_)\n",
        "\n",
        "# Log Likelihood Score\n",
        "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
        "\n",
        "# Perplexity\n",
        "print(\"Model Perplexity: \", best_lda_model.perplexity(data_vectorized))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xMIhY0PGzeIH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get Log Likelyhoods from Grid Search Output\n",
        "n_topics = [10, 15, 20, 25, 30]\n",
        "log_likelyhoods_5 = [round(gscore.mean_validation_score) for gscore in model.grid_scores_ if gscore.parameters['learning_decay']==0.5]\n",
        "log_likelyhoods_7 = [round(gscore.mean_validation_score) for gscore in model.grid_scores_ if gscore.parameters['learning_decay']==0.7]\n",
        "log_likelyhoods_9 = [round(gscore.mean_validation_score) for gscore in model.grid_scores_ if gscore.parameters['learning_decay']==0.9]\n",
        "\n",
        "# Show graph\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(n_topics, log_likelyhoods_5, label='0.5')\n",
        "plt.plot(n_topics, log_likelyhoods_7, label='0.7')\n",
        "plt.plot(n_topics, log_likelyhoods_9, label='0.9')\n",
        "plt.title(\"Choosing Optimal LDA Model\")\n",
        "plt.xlabel(\"Num Topics\")\n",
        "plt.ylabel(\"Log Likelyhood Scores\")\n",
        "plt.legend(title='Learning decay', loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VIurW-pr00GV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}